import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.retrievers import ContextualCompressionRetriever
from langchain_community.cross_encoders import HuggingFaceCrossEncoder
from langchain.retrievers.document_compressors import CrossEncoderReranker

# Importe LLM, Prompt, Chain (como no Naive RAG)
# ...

# --- CONFIGURAÇÃO ---
PDF_PATH = "caminho/para/os_sertoes.pdf" 
EMBEDDING_MODEL = "BAAI/bge-m3"
# Modelo de Reranker (Cross-Encoder)
RERANK_MODEL = "BAAI/bge-reranker-base" 
# llm = ...

# --- 1. CRIAR O RETRIEVER BASE (Igual ao Naive RAG) ---
loader = PyPDFLoader(PDF_PATH)
docs = loader.load()
text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
splits = text_splitter.split_documents(docs)

print("Criando embeddings e vetorizando...")
embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)
vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)

# O retriever base busca MAIS documentos (ex: k=20)
base_retriever = vectorstore.as_retriever(search_kwargs={"k": 20})

# --- 2. CONFIGURAR O RERANKER (Cross-Encoder) ---
print("Configurando o Reranker...")
cross_encoder_model = HuggingFaceCrossEncoder(model_name=RERANK_MODEL)

# O compressor usa o cross-encoder para reordenar e filtrar
compressor = CrossEncoderReranker(model=cross_encoder_model, top_n=3) # Pega os 3 melhores

# --- 3. CRIAR O RETRIEVER COM COMPRESSÃO (Rerank) ---
# Este retriever executa o base_retriever e DEPOIS aplica o compressor
retriever = ContextualCompressionRetriever(
    base_compressor=compressor, 
    base_retriever=base_retriever
)

# --- 4. CRIAR A CADEIA RAG (Igual ao Naive RAG) ---
prompt = ChatPromptTemplate.from_template(...) # (copie o prompt do Naive RAG)

rag_chain_rerank = (
    {"context": retriever | format_docs, "input": RunnablePassthrough()}
    | prompt
    # | llm
    # | StrOutputParser()
)

# --- 5. EXECUTAR AS PERGUNTAS ---
print("\n--- Respostas do Rerank RAG ---")
for pergunta in lista_perguntas: # (use a mesma lista)
    print(f"\nPergunta: {pergunta}")
    # resposta = rag_chain_rerank.invoke(pergunta)
    # print(f"Resposta: {resposta}")
    print("Resposta: [LLM desativado neste exemplo]")
