import os
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.storage import InMemoryStore # Para armazenar os 'parents'
from langchain.retrievers import ParentDocumentRetriever

# Importe LLM, Prompt, Chain (como no Naive RAG)
# ...

# --- CONFIGURAÇÃO ---
PDF_PATH = "caminho/para/os_sertoes.pdf" 
EMBEDDING_MODEL = "BAAI/bge-m3"
# llm = ...

# --- 1. CARREGAR DOCUMENTO ---
loader = PyPDFLoader(PDF_PATH)
docs = loader.load()

# --- 2. CRIAR OS SPLITTERS (Parent e Child) ---

# Este splitter define os documentos "parent" (contexto maior)
parent_splitter = RecursiveCharacterTextSplitter(
    chunk_size=2000, 
    chunk_overlap=400
)

# Este splitter define os documentos "child" (para busca precisa)
# O tamanho do child deve ser menor que o do parent
child_splitter = RecursiveCharacterTextSplitter(
    chunk_size=400, 
    chunk_overlap=100
)

# --- 3. CRIAR VECTOR STORE E DOCSTORE ---
embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL)

# O Vector Store armazena os embeddings dos 'child' chunks
vectorstore = FAISS(
    embedding_function=embeddings,
    index=None, # Será preenchido pelo retriever
    docstore=None, # Será preenchido pelo retriever
    index_to_docstore_id={} # Será preenchido pelo retriever
)

# O Docstore armazena o *texto* dos 'parent' chunks
docstore = InMemoryStore()

# --- 4. CRIAR O PARENT DOCUMENT RETRIEVER ---
retriever = ParentDocumentRetriever(
    vectorstore=vectorstore,
    docstore=docstore,
    child_splitter=child_splitter,
    parent_splitter=parent_splitter,
)

# Adiciona os documentos ao retriever (ele cuida de splitar, embutir e linkar)
print("Adicionando documentos ao ParentDocumentRetriever...")
# 'add_documents' é depreciado, usamos 'add_documents' no vectorstore e docstore
# A forma moderna é um pouco mais manual, mas o conceito é o mesmo.
# Vamos usar o método antigo 'add_documents' para simplicidade, se sua versão do langchain suportar.
# Se não, a lógica é:
# 1. Splitar parents
# 2. Splitar children de cada parent
# 3. Adicionar children ao vectorstore
# 4. Adicionar parents ao docstore
# O 'ParentDocumentRetriever' simplifica isso.
retriever.add_documents(docs, ids=None)

# --- 5. CRIAR A CADEIA RAG (Igual ao Naive RAG) ---
# O prompt e a cadeia são idênticos, só muda o 'retriever'
prompt = ChatPromptTemplate.from_template(...) # (copie o prompt do Naive RAG)

rag_chain_parent = (
    {"context": retriever | format_docs, "input": RunnablePassthrough()}
    | prompt
    # | llm
    # | StrOutputParser()
)

# --- 6. EXECUTAR AS PERGUNTAS ---
print("\n--- Respostas do Parent RAG ---")
for pergunta in lista_perguntas: # (use a mesma lista)
    print(f"\nPergunta: {pergunta}")
    # resposta = rag_chain_parent.invoke(pergunta)
    # print(f"Resposta: {resposta}")
    print("Resposta: [LLM desativado neste exemplo]")
